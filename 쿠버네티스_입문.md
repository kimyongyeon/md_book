## 1. 도커

- 교재: 도커/쿠버네티스를 활용한 컨테이너 개발 실전 입문 .

### 도커란 무엇인가?
`도커`는 컨테이너형 가상화 기술을 구현하기 위한 상주 애플리케이션과 이 애플리케이션을 조작하기 위한 명령형 도구로 구성되는 프로덕트다. 애플리케이션 배포에 특화돼 있기 때문에 애플리케이션 개발 및 운영을 컨테이너 중심으로 할 수 있다.

### 도커의 역사
2013년 봄 닷클라우드사의 엔지니어였던 솔로몬 하익스가 최초로 도커를 오픈 소스로 공개했다. 이때부터 그 편리함 덕분에 도커는 점차 널리 퍼져 나갔다. 

오케스트레이션 도구 Fig를 인수 - 현재의 도커 컴포즈 

2014년부터는 도커 관련 컨퍼런스 DockerCon이 매년 개최

### 도커의 기본 개념
도커는 컨테이너형 가상화를 구현하기 위한 상주 애플리케이션과 이를 관리하는 명령형 도구로 구성된다. 

#### 컨테이너형 가상화 기술
도커는 `컨테이너형 가상화 기술`(운영체제수준가상화)을 사용한다. 
도커 이전에는 LXC가 유명했는데 도커도 초기에는 컨테이너형 가상화를 구현하는데 LXC를 런타임으로 사용(현재runC를 사용) 했다.
컨테이너형 가상화를 사용하면 소프트웨어 없이도 운영 체제의 리소스를 격리해 가상 운영 체제로 만들 수 있다. 이 가상 운영 체제를 컨테이너라고 한다. 
![imgUrl](https://miro.medium.com/max/1400/1*wOBkzBpi1Hl9Nr__Jszplg.png)


#### 애플리케이션이 중심이 되는 도커
문제점: LXC는 설정의 차이로 다른 OS에서 구동이 되지 않는 현상이 발생함.
도커와 LXC의 차이점
- 호스트 운영체제의 영향을 받지 않는 실행환경(Docker Engine을 이용한 실행 환경 표준화)
- DSL(Dockerfile)을 이용한 컨테이너 구성 및 애플리케이션 배포 정의
- 이미지 버전 관리
- 레이어 구조를 갖는 이미지 포맷(차분 빌드가 가능함)
- 도커 레지스트리(이미지 저장 서버 역할을 함)
- 프로그램 가능한 다양한 기능의 API
도커는 컨테이너 정보를 Dockerfile 코드로 관리할 수 있다. 이 코드를 기반으로 복제 및 배포가 이루지기 때문에 재현성이 높은 것이 특징이다. 

### 도커 스타일 체험하기
1. 스크립트 작성
```
#!/bin/sh
echo "hello, world!"
```  

2. 스크립트를 도커에 담아보자.
```
FROM ubuntu:16.04

COPY helloworld /usr/local/bin
RUN chmod +x /usr/local/bin/helloworld

CMD ["helloworld"]
```  

*1. FROM: 운영체제 정의*  
*2. COPY: 셀스크립트 파일을 도커컨테이너 안의 /usr/local/bin에 복사*  
*3. RUN: 도커 컨테이너 안에서 어떤 명령을 수행*  
*4. CMD: 완성된 이미지를 도커 컨테이너로 실행하기 전에 먼저 실행할 명령을 정의 한다.*  

3. Dockerfile을 사용해 이미지를 빌드
```
$ docker image build -t helloworld:latest .
```  

4. 도커 실행
```
$ docker container run helloworld:latest
```  

### 더 실용적인 예제
한번 실행되면 끝나는 어플리케이션이 아닌 계속 실행된 상태 어플리케이션 만들기  
node.js 버전의 기반 이미지를 이용하되, npm으로 모듈을 추가 설치하거나 애플리케이션 빌드를 컨테이너 안에서 수행해 이미지를 만든다.  
호스트 운영체제에 node.js나 npm을 설치할 필요가 없다.  
<u>이건 혼자서 만들어 보라는 소리?</u>  

### 도커를 사용하는 의의
- 변화하지 않는 실행환경으로 멱등성 확보
- 코드를 통한 실행 환경 구축 및 애플리케이션 구성
- 실행 환경과 애플리케이션의 일체화로 이식성 향상
- 시스템을 구성하는 애플리케이션 및 미들웨어의 관리 용이성

웹 어플리케이션의 프론트앤드에 아파치나 엔진엑스 같은 웹서버를 두는 것도 복잡한 절차 없이 컨테이너로 설정할 수 있게 된다. 미들웨어를 포함하는 시스템 구성 역시 설정 파일로 정의할 수 있다. 도커를 도입하면 개발 및 운영 업무가 쉬워진다.
> 도커 도입이 진정 개발 및 운영 업무를 쉽게 만들어 줄까? - 각자의 의견을 듣고 싶어요!

#### 도커 도입전 문제점 
> B 서버에서도 같은 애플리케이션을 배포하고 싶은데, 애플리케이션 A 서버와 다르게 동작하네  
> 모든 서버에 같은 아카이브를 배포하고 싶은데...,  
> 서버 설정과 설치된 라이브러리가 서버마다 다르면 어쩌지?  
> B 서버에 설치된 라이브러리가 버전은 낮은 거였네, 업데이트 해야 겠다.  
> 서버 상태를 똑같이 유지하는 수단이 필요하겠어  

#### 근복적인 원인
*인프라의 가변성을 허용*

애플리케이션을 항상 뭔가에 의존성을 갖는다. 운영체제는 물론이고, CPU나 메모리 같은 컴퓨터 리소스, 언어 런타임, 라이브러리, 애플리케이션 내부적으로 별도 프로세스로 실행하는 다른 애플리케이션 등 다양한 요소에 의존성을 가질 수 있다. 

각 서버에 배포된 애플리케이션이 동일하다면, 애플리케이션이 의존하는 환경의 차이를 가능한 한 배제 하는 것이 이 문제를 해결하는 지름길이다. 

#### 코드로 관리하는 인프라와 불변 인프라
코드로 관리하는 인프라는 코드 기반으로 인프라를 정의한다는 개념이다. 
서버를 어떻게 구성할 것인지, 어떤 라이브러리 도구를 설치할지를 코드로 정의하고 셰프나 앤서블 같은 프로비저닝 도구로 서버를 구축한다. 수작업이 개입할 여지를 줄이고 코드 중심으로 바꿈으로써 쉽게 같은 구성의 서버 여러 대를 복제할 수 있다. 

***코드로 관리하는 인프라 역시 만병 통치약은 아니다.***
아래의 경우를 보자.
```bash 
$ nodebrew install-binary stable
```
이것은 Node.js 버전 관리 도구인 nodebrew에서 안정 버전(stable)을 설치하도록 설정하는 명령이다. stable이 가리키는 버전은 생각보다 자주 변하기 때문에 이런 방식으로는 항상 같은 결과가 보장되지 않는다. 환경 차이 문제를 피하려면 언제든 몇 번을 실행해 같은 결과가 보장되는 멱등성을 확보해야 한다. 애플리케이션이 의존하는 런타임이나 라이브러리 모두가 확실하게 특정 버전으로 설치되도록 코드를 작성해야 한다.

그러나 `항구적인 코드`를 계속 작성하는 것은 운영 업무에 부담을 주기 쉽다.

이 문제의 해결방안은 `불변 인프라 개념`이다. 불변 인프라는 `어떤 시점의 서버 상태를 저장`해 복제할수 있게 하자는 개념이다. 제대로 설정된 상태의 서버를 항상 사용할 수 있다는 점이 가장 큰 장점이다. 

서버에 변경을 가하고 싶은 경우에는 기존 인프라를 수정하는 대신 `새로운 서버를 구축`하고 `그 상태를 이미지로 저장`한 다음 그 `이미지를 복제`한다. 한번 설정된 서버는 수정 없이 파기되므로 멱등성을 신경쓸 필요조차 없다. 

도커를 사용하면 코드로 관리하는 인프라와 불변 인프라의 두 개념을 간단하고 낮은 비용으로 실현할 수 있다. 
인프라 구성이 Dockerfile로 관리되므로 코드로 관리하는 인프라는 도커의 대원칙이다. 

도커는 도커 이미지(Dockerfile)로 서버 구성을 코드로 관리할 수 있다. 그러므로 기존 컨테이너를 빠르게 폐기하고 새로이 구축할 수 있다. 코드로 관리하는 인프라와 불변 인프라라는 두 개념 모두를 쉽게 구현할 수 있는 도구라고 할 수 있다. 

최근 아마존이나 GCP 같은 플랫폼은 가상머신을 쉽게 만들고 파기할 수 있는 시대이긴 하지만 호스트 가상화 방식에서는 가상머신을 시작하는데 적어도 1분에서 수분까지 시간이 걸린다. 호스트 가상화 기술은 가상화 소프트웨어로 컴퓨터 리소스를 추상화하는 방식이기 때문이다. 클라우드에서 도커를 사용할 때도 이런 점을 감안하는 것이 좋다.

#### 애플리케이션과 인프라 묶어 구축하기
도커에서 제공하는 인프라 관리와 애플리케이션 배포 개념도 도커의 장점 중 하나다. 
운영체제와 어플리케이션을 함께 담은 상자 같은 개념이다
컨테이너는 도커 이미지 형태로 저장하고 재사용할 수 있다.

### 애플리케이션 구성 관리의 용이성
도커 컨테이너는 애플리케이션과 인프라를 함께 담은 상자이다. 일정 규모를 넘는 시스템은 주로 여러개의 애플리케이션과 미들웨어를 조합하는 형태로 구성한다.
도커를 사용함으로써 배포 작업이 매우 쉬워지기는 했지만, 복잡한 시스템을 한덩어리로 동작시키기는 쉽지 않다. 

#### 도커 컨테이너 오케스트레이션 시스템
여러 컨테이너를 사용하는 애플리케이션을 쉽게 관리할 수 있도록 도커 컴포즈라는 도구를 제공한다. 

```yaml
version: "3"
services: 
    web:
        image: gihyodocker/web
        ports:
            - "3000":"3000"
        enviroment:
            REDIS_TARGET: redis
        depends_on:
            - redis
    redis:
        image: "redis:alpine"
```  

도커와 `도커 컴포즈`를 통해 `여러 애플리케이션과 미들웨어의 의존관계를 간결한 코드`로 관리할 수 있다. `도커 컴포즈`가 `단일 서버`를 넘어 `여러 서버`에 걸쳐 있는 여러 컨테이너를 관리할 수 있도록 한 도구가 `도커 스윔`이다. 
`도커 스윔`은 컨테이너 증가 혹은 감소는 물론이고 노드의 리소스를 효율적으로 활용하기 위한 컨테이너 배치 및 로드 밸런싱 기능 등 더욱 실용적인 기능을 갖추고 있다.
또, 배포 시에도 롤링 업데이트(오래된 컨테이너와 새로운 컨테이너를 단계적으로 서비스에 교체 투입하는 것)가 가능해 운영 면에서도 장점이 많다. 여러 서버에 걸쳐 있는 여러 컨테이너를 관리하는 기법을 컨테이너 `오케스트레이션` 이라고 한다.

컨테이너 오케스트레이션 분야에서 사실상 표준으로 자리 잡은 것은 쿠버네티스다. 쿠버네티스는 구글이 오랫동안 컨테이너를 운영하면서 얻은 노하우를 담은 오픈소스 소프트웨어다
도커 스윔보다 기능이 충실하며 확장성이 높다.  

### 운영 환경에서 빛을 발하는 도커
> - 도커의 신뢰성에 대한 의문
> - 성능 면에서의 우려
> - 현실적으로 운영이 가능한지에 대한 우려  

이러한 생각은 쓸데없는 생각이다. 운영 환경이야말로 도커가 빛을 발하는 자리다. 최근 몇년동안 도커는 전 세계 운영 환경에 도입됐으며 확실히 주류에 편입되고 커뮤니티의 성숙과 함께 신뢰성도 인정받았다. 성능 면에서도 스케일 아웃이 쉽다는 장점이 있음에도 오버헤드는 매우 적다.

데이터 스토어처럼 도커를 운영하기 어려운 분야도 존재한다. 

높은 이식성이라는 장점을 고려하면 도커는 운영환경에서 그야말로 제 능력을 발휘할 수 있는 기술이다. 이미 여러 실적을 거둔 바 있으며 클라우드에서도 매니지드 서비스를 통해 쉽게 다룰 수 있다. 

### 새로운 개발 스타일
인프라와 애플리케이션의 설정을 모두 코드 수준에서 쉽게 수정할 수 있게 됐다.
기존에는 명확했던 인프라 엔지니어와 서버 사이드 엔지니어의 영역 구분이 점점 희미해지고 있다. 
마이크로서비스 + 도커 궁합짱
개발에 외부API를 사용하는 경우에도 도커가 제공하는 목업 서버 개발 환경을 사용하는 경우가 늘고 있다. 안드로이드 개발을 예로 들면 도커가 CI 속도를 빠르게 하는 데 효율적이다.

도커는 인프라 엔지니어와 서버 사이드 엔지니어의 전유물이 아니다. 현대적인 개발을 수행한다면 프론트 엔드 엔지니어와 모바일 애플리케이션 엔지니어에게도 기초 기술이 될 것이다.


### 로컬 도커 환경 구축하기 
여기서는 윈도우용/macOS용 도커를 기준으로 설치하는 방법을 설명한다. 

#### 도커설치 파일 아래 다운로드 후 진행
도커는 커뮤니티 무료 버전을 받자  
https://hub.docker.com/editions/community/docker-ce-desktop-windows?tab=description  

#### 윈도우/macOS용 도커 기본 설정
- 도커 자동실행 체크  
- 자동 업데이트 확인 체크해제  
- 호스트 운영 체제 디렉토리 마운트  
- 가상 디스크 용량 설정  
- CPU 코어 및 메모리 할당  
- 프록시  
- 비보안 레지스트리  
- 쿠버네티스 체크 설정  
- 모든 데이터 삭제: 도커 막 설치한 초기상태 된다.  
- 도커 제거: 컨테이너 및 이미지도 모두 함께 파기된다  
- 도커 툴박스 설치: 가상머신에서 설치  

> 도커CE, EE 선택중 기업용에 걸맞은 기술 지원이 필요하다면 도커 EE의 도입을 검토해야 함.

## 도커 컨테이너 배포 
도커의 기본 조작 방법을 배우고, 애플리케이션을 배포하는 과정까지 알아본다.

### 컨테이너로 애플리케이션 실행하기
- 도커이미지: 도커컨테이너를 구성하는 파일시스템과 애플리케이션 설정을 하나로 합친것으로 컨테이너를 생성하는 템플릿 역할을 한다.  
- 도커컨테이너: 도커 이미지를 기반으로 생성되며, 파일시스템과 애플리케이션이 구체화돼 실행되는 상태  

### 도커이미지와 도커 컨테이너

```
$ docker image pull gihyodocker/echo:latest
$ docker container run -t -p 9001:8000 gihyodocker/echo:latest
$ curl http://localhost:9001
```

### 간단한 애플리케이션과 도커 이미지 만들기


1. 노드를 설정한다.  
```
npm init -f
npm i --save express build
```  

2. 소스를 작성한다.  
```javascript
// 디팬던시
var express = require('express');
var uuid = require('uuid');

var app = express();
var id = uuid.v4();
var port = 3000;

app.get('/', function (req, res) {
res.send(id)
});

app.listen(port, function () {
console.log('Example app listening on port: ' + port);
});
```  

3. 실행한다.  
```bash
node index.js
```  

4. 주의  
> node_modules을 직접 복사하는 일이 없도록 .dockerignore 파일을 작성한다. 

5. Dockerfile 작성  

```yaml
FROM node:6
COPY package.json /src/package.json
RUN cd /src; npm install
COPY . /src
EXPOSE 3000
WORKDIR /src

CMD node index.js
```  

#### FROM 인스트럭션
베이스 이미지 지정

#### RUN 인스트럭션
명령 실행

#### COPY 인스트럭션
파일 복사

#### CMD 인스트럭션
컨테이너 실행 명령

#### 그외
- LABEL: 라벨 설정  
- EXPOSE: 포트 포워딩  
- ENV: 환경변수  
- ADD: 파일/디렉토리 추가  
- COPY: 파일 복사  
- ENTRYPOINT: 컨테이너 실행 명령  
- VOLUME: 볼륨 마운트  
- USER: 사용자 지정  
- WORKDIR: 작업 디렉토리  
- ARG: Dockerfile 안의 변수  
- ONBUILD: 빌드 완료 후 실행되는 명령  
- STOPSIGNAL: 시스템 콜 시그널 설정  
- HEALTHCHECK: 컨테이너의 헬스 체크  
- SHELL: 기본 쉘 설정    

### 도커 이미지 빌드

```
$ docker build --tag node-nginx:test .
$ docker images
```  
### 도커 컨테이너 실행

```
$ docker run --name node-nginx-instance -p 3000:3000 node-nginx:test
$ docker ps
```  

### 포트 포워딩

애플리케이션은 3000 포트를 리스닝 하고 있지만, 이 포트는 컨테이너 포트라고 해서 컨테이너 안에 한정된 포트이다. 컨테이너 안에서 호출하면 3000을 호출하면 응답을 제대로 받겠지만 외부에서 찌르면 받을 수 없다. 밖에서 온 요청을 컨테이너 안에 있는 어플리케이션에 전달해줘야 하는데 이 역할을 담당하는 것이 바로 도커의 포트 포워딩이다. 

-p 옵션값은 호스트_포트:컨테이너_포트 형식으로 기술하면 된다. 

호스트 포트를 다음과 같이 생략 가능하다.  
이런 경우에는 빈 포트가 에퍼메랄 포트로 자동 할당된다.  

```
$ docker container run -d -p 8080 node-nginx:test
```

## 도커 이미지 다루기 

도커 사용법은 크게 이미지를 다루는것과 컨테이너를 다루는 것으로 나눠 진다.  
도커 이미지는 도커 컨테이너를 만들기 위한 템플릿이다.  
도커 이미지는 우분투 같은 운영 체제로 구성된 파일 시스템은 물론, 컨테이너 위에서 실행하기 위한 애플리케이션이나 그 의존 라이브러리, 도구에 어떤 프로세스를 실행할지 등의 실행환경의 설정정보까지 포함하는 아카이브다.  

컨테이너의 템플릿역할을 하는 이미지를 만드는 과정을 일반적으로 `도커 이미지를 빌드한다.` 라고 한다.  그리고 컨테이너를 실행할 때 이 빌드된 이미지를 사용한다.  
이미지를 빌드하는 명령어인 docker image build 부터 시작해 이미지를 다루는 기본 명령을 하나씩 살펴볼 것이다. 그리고 마지막으로 도커 허브에 이미지를 등록하는 과정까지 수행해 봄으로써 직접 만든 이미지를 다른 사람이 이용할 수 있게 하는 단계를 목표로 한다.  

중요한것을 놓치기도 한다. 아래와 같이 검색한다.  

```
$ docker help
```  

### docker image build - 이미지 빌드
docker image build -t 이미지명[:태그명] Dockerfile의_경로  
실전 예제)  

```
$ docker image build -t example/echo:latest
```  

-f 옵션  
docker image build 명령은 기본으로 Dockerfile이라는 이름으로 된 Dockerfile을 찾는다. 그 외 파일명으로 된 Dockerfile을 사용하려면 -f 옵션을 사용해야 한다. 예를 들어 Dockerfile-test라는 이름으로 된 Dockerfile을 사용하려면 다음과 같이 한다.  

```
$ docker image build -f Dockerfile-test -t example/echo:latest .
```

--pull 옵션  
docker image build 명령으로 이미지를 빌드하려면 Dockerfile의 FROM 인스트럭션에 지정한 이미지를 레지스트리에서 내려받은 후, 이를 베이스 이미지로 해서 새로운 이미지를 빌드한다.  

이렇게 레지스트리에서 받아온 도커 이미지는 일부러 삭제하지 않는 한 호스트 운영 체제에 저장된다.  
그러므로 이미지를 빌드할 때 매번 베이스 이미지를 받아오지는 않는다. 그러나 --pull 옵션을 사용하면 매번 베이스 이미지를 강제로 새로 받아온다.  

```
$ docker image build --pull=true -t example/echo:latest .
```  
### docker search - 이미지 검색

docker search 명령을 사용하면 도커 허브에 등록된 레포지토리를 검색할 수 있다.  

```
$ docker search --limit 5 mysql
```

### docker image pull - 이미지 내려받기

```
$ docker image pull jenkins:latest
```

### docker image ls - 보유한 도커 이미지 목록 보기

```
$ docker image ls
```

### docker image tag - 이미지에 태그 붙이기

```
$ docker image ls 
$ docker image tag example/echo:latest example/echo:0.1.0
```

### docker image push - 이미지를 외부에 공개하기

```
$ docker image tag example/echo:latest stormcattest/echo:latest
$ docker image push stormcattest/echo:lastest
```

> Dockerfile에는 패스워드나 API 키값 같은 민감한 정보가 포함되지 않도록 주의한다. 

## 도커 컨테이너 다루기

도커 컨테이너는 이미지를 바탕으로 만든다.  
겉에서 본 도커 컨테이너는 가상 환경이다.  
파일 시스템과 애플리케이션이 함께 담겨 있는 박스라고 보면 된다.  


### 도커 컨테이너의 생명주기

도커 컨테이너는 실행 중, 정지, 파기의 3가지 상태를 갖는다. 이것을 도커 컨테이너의 생애주기라고 한다. `docker container run` 명령으로 컨테이너를 최초 실행한 시점의 상태는 실행중이다.  
각 컨테이너는 같은 이미지로 생성했다고 하더라도 별개의 상태를 갖는다. 이 점이 상태를 갖지 않는 도커 이미지와 컨테이너의 큰 차이의 하나다.

#### 실행중 상태

docker container run 명령의 인자로 지정된 도커 이미지를 기반으로 컨테이너가 생성되면 이 이미지를 생성했던 Dockerfile에 포함된 CMD및 ENTRYPOINT 인스트럭션에 정의된 애플리케이션이 실행된다.  
이 애플리케이션이 실행 중인 상태가 컨테이너의 실행 중 상태가 된다.  
실행이 끝나면 정지 상태가 된다.  HTTP 서버 애플리케이션의 실행주기는 길다.  

#### 정지 상태

실행 중 상태에 있는 컨테이너를 사용자가 명시적으로 정지하거나 컨테이너에서 실행된 애플리케이션이 정상/오류 여부를 막론하고 종료된 경우에는 컨테이너가 자동으로 정지 상태가 된다.  
컨테이너를 정지시키면 가상 환경으로서는 더 이상 동작하지 않지만, 디스크에 컨테이너가 종료되던 시점의 상태가 저장돼 남는다. 그러므로 정지시킨 컨테이너를 다시 실행할 수 있다.

#### 파기 상태

정지상태의 컨테이너는 명시적으로 파기하지 않는 이상 디스크에 그대로 남아 있다. 사용하지 않는 컨테이너는 디스크를 낭비하기 때문에 삭제를 하는것 좋다. 한번 파기한 컨테이너는 다시는 실행할 수 없다는 점에 유의하기 바란다. 

### docker container run - 컨테이너 생성 및 실행

docker container run 명령은 도커 이미지로부터 컨테이너를 생성하고 실행하는 명령어이다.  

```
$ docker container run -d -p 9000:8000 example/echo:latest
```

-p 옵션을 사용해 호스트 쪽 포트 9000을 컨테이너 쪽 포트 8000으로 포트 포워딩했으므로 http 요청을 컨테이너에 전달 할 수 있다.

```
$ curl http://localhost:9000
```

#### docker container run 명령어 인자

CMD 인스트럭션을 오버라이드 할 수 있다.

```
$ docker image pull alpine:3.7
$ docker container run -it alpine:3.7 # 셀에 들어감.
$ docker container run -it alpine:3.7 uname -a 
```

#### 컨테이너에 이름 붙이기

docker container ls 명령으로 컨테이너 목록을 보면 NAMES 칼럼에 무작위 단어로 지어진 이름을 볼 수 있다.

```
$ docker container run -t -d --name gihyo-echo example/echo:latest
$ docker container ls
```

이름 붙인 컨테이너는 개발용으로는 비교적 자주 사용되지만, 운영 환경에서는 거의 사용되지 않는다.  
같은 이름의 컨테이너를 새로 실행하려면 같은 이름을 갖는 기존의 컨테이너를 먼저 삭제해야 하기 때문이다. 이 때문에 많은 수의 컨테이너를 계속 생성 및 실행하고, 정지시켰다가 파기시키는 과정을 반복하는 운영환경에는 적합하지 않다.

> ***도커에서 자주쓰는 옵션 설명***
> 1. -i: 컨테이너를 실행할 때 컨테이너 쪽 표준 입력과 연결을 그대로 유지한다.
> 2. -t: 유사 터미널 기능을 활성화
> 3. -it: 위 두기능을 같이 쓸때 사용
> 4. --rm: 컨테이너를 종료할 때 컨테이너를 파기하도록 하는 옵션

### docker container ls - 도커 컨테이너 목록 보기 

컨테이너 목록을 출력하는 명령어  
docker container ls 에서 확인이 가능하도록 다음과 같이 2개의 컨테이너를 실행한다.

```
$ docker container run -t -d -p 8080 --name echo1 example/echo:latest
$ docker container run -t -d -p 8080 --name echo2 example/echo:latest
```

#### 컨테이너 ID만 추출하기

docker container ls 명령으로 컨테이너 ID와 생성 시 사용한 이미지 등의 정보를 확인할 수 있다. 이때 -q 옵션을 사용하면 컨테이너 ID(축약형)만 추출할 수 있다. 컨테이너를 다루려면 이 컨테이너 ID가 필용하므로 이 명령 역시 자주 사용하게 될 것이다. 

```
$ docker container ls -q
```

#### 컨테이너 목록 필터링 하기 
docker container ls로 특정 조건을 만족하느 컨테이너의 목록을 보려면 --filter 옵션을 사용하면 된다. 

```
$ docker container ls --filter "name=echo1"
```

#### 중복된 컨테이너 목록 보기

-a 옵션을 사용하면 이미 종료된 컨테이너를 포함한 컨테이너 목록을 볼 수 있다. 

```
$ docker container ls -a
```

### docker container stop - 컨테이너 정지하기

실행 중인 컨테이너를 종료하려면 docker container stop 명령을 사용한다. 

```
$ docker container run -d -p 9000:8080 example/latest
$ docker container stop [id]
```

### docker container restart - 컨테이너 재시작하기

파기하지 않은 정지 상태 컨테이너는 docker container restart 명령으로 재시작할 수 있다.

```
$ docker container restat echo 
```

### docker container rm - 컨테이너 파기하기

컨테이너를 정지하는 명령은 docker container stop 이고, 정지시킨 컨테이너를 완전히 파기하려면 docker container ru 명령을 사용한다. 

```
$ docker container ls --filter "status=exited"
$ docker container rm [id]
```

실행중인 컨테이너를 지우는 방법

```
$ docker container rm -r [id]
```

#### docker container run --rm을 사용해 컨테이너를 정지할 때 함께 삭제하기 

실행이 끝나면 자동으로 컨테이너를 쓰지 않으므로 삭제하는 방법 --rm 

```
$ echo '{"version":100}' | docker container run -i --rm gihyodocker/jq:1.5 '.version'
```

### docker container logs - 표준 출력 연결하기

docker container logs 명령을 사용하면 현재 실행 중인 특정 도커 컨테이너의 표준 출력 내용을 확인할 수 있다. 

```
$ docker container logs -f $(docker container ls --filter "ancestor=jenkins" -q)
```

### docker container exec - 실행중인 컨테이너에서 명령 실행하기 

실행중인 컨테이너에서 원하는 명령을 실행 할 수 있다. 

```
$ docker container run -t -d --name echo --rm example/echo:latest
$ docker container exec -it echo sh
```

### docker container cp - 파일 복사하기

docker container cp 명령은 컨테이너끼리 혹은 컨테이너와 호스트 간에 파일을 복사하기 위한 명령이다. Dockerfile에 포함된 COPY 인스트럭션은 이미지를 빌드할 때 호스트에서 복사해 올 파일을 정의하는 것이고, docker container cp 명령은 실행 중인 컨테이너와 파일을 주고받기 위한 명령이다. 

```
$ docker container cp echo:/echo/main.go .
$ docker container cp dummy.txt echo:/tmp
$ docker container exec echo ls /tmp | grep dummy
```

## 운영과 관리를 위한 명령

```
$ docker container prune
```

실행중인 정지된 모든 컨테이너 삭제

```
$ docker image prune
```

태그가 붙지 않은 모든 이미지를 삭제

```
$ docker system prune
```

사용하지 않는 도커 이미지 및 컨테이너, 볼륨, 네트워크, 등 모든 도커 리소스를 일괄적으로 삭제

### docker contaner stats - 사용 현황 확인하기

```
$ docker container stats
```

## 도커 컴포즈로 여러 컨테이너 실행하기

의존성 시스템  
도커 컨테이너 = 단일 애플리케이션  

### docker-compose 명령으로 컨테이너 실행하기 

여러 컨테이너 실행을 한번에 관리할 수 있게 해줌

```
$ docker-compose version
docker-compose version 1.16.1, build 6d1ac21
docker-py version: 2.5.1
CPython version: 2.7.13
OpenSSL version: OpenSSL 1.0.1t  3 May 2016
```

docker-compose.yml 파일 작성

```yaml
version: "3"
services:
    echo:
        image: example/latest
        ports:
        - 9000:8000
```

```bash
$ docker-compose up -d
$ docker container ls
$ docker-compose down
```

재빌드

```bash
$ docker-compose up -d --build
```

## 컴포즈로 여러 컨테이너 실행하기

컴포즈를 사용한 구성 관리 기능의 진가는 여러 컨테이너를 실행할 때 발휘된다.  
같은기술: 엔서블, 테라폼, 클라우드포메이션 등...  

### 젠킨스 컨테이너 실행하기

docker-compose.yml 작성

```yaml
version: "3"
services: 
    master:
        container_name: master
        image: jenkinsci/jenkins:2.142-slim
        ports:
        - 8080:8080
        volumes:
        - ./jenkins_home:/var/jenkins_home
```

도커 빌드

```bash
$ docker-compose up
```  

ubuntu에서는 서치가 안된다.  

### 마스터 젠킨스 용 SSH 키 생성 

실용적인 예제 = 마스터 + 슬레이브 
먼저 준비 작업으로 마스터가 슬레이브에 접속할 수 있도록 마스터 컨테이너에 SSH 키를 생성한다. 나중에 마스터가 슬레이브와 소통할 수 있으려면 이 키가 반드시 필요하므로 꼭 만들어야 한다.  
지금 실행중인 첫 번째 컨테이너가 마스터 젠킨스 역할을 할 것이다.

```bash
$ docker container exec -it master ssh-keygen -t rsa -C ""

```

### 슬레이브 젠킨스 컨테이너 생성

슬레이브 컨테이너는 slave01로 각각 이름을 붙인다. 

```yml
version: "3"
services: 
    master:
        container_name: master
        image: jenkinsci/jenkins:2.142-slim
        ports: 
        - 8080:8080
        volumes:
        - ./jenkins_home:/var/jenkins_home
        links:
        - slave01
slave01:
    container_name: slave01
    image: jenkinsci/ssh-slave
    envirment:
        - JENKINS_SLAVE_SSH_PUBKEY=ssh-rsa AAAAsdfsdfsdf

```  

#### SSH 접속 허용 설정

SSH로 접속하는 슬레이브 용도로 구성된 도커 이미지 jenkinsci/ssh-slave를 사용한다. jenkinsci/ssh-slave 이미지에 다시 환경 변수 JENKINS_SLAVE_SSH_PUBKEY를 설정하는데, SSH로 접속하는 상대가 이 키를 보고  
마스터 젠킨스임을 식별하게 된다. 이 환경변수는 호스트파일 시스템의 ./jenkins_home/.ssh/id_rsa.pub 의 내용을 그대로 붙여 넣으면 된다. 슬레이브 컨테이너 안에서 키를 받아오거나 설정해서는 안 되며, 외부 환경  
변수로 받아 오게 해야 한다.  

#### SSH 접속 대상 설정 

슬레이브와 어떻게 통신할지에 대한 문제가 남음 - IP 주소를 찾아 설정하는 방법도 있지만, 컴포즈를 사용하면 좀 더 깔끔하게 이 문제를 해결할 수 있다.  
links 요소를 사용해 다른 services 그룹에 해당하는 다른 컨테이너와 통신하면 된다.  
여기서 master에 slave01에 대한 links를 설정했다. 이것으로 master에서 slave01이라는 이름으로 슬레이브 컨테이너를 찾아갈 수 있다.

#### 컨테이너 간의 관계 정리 및 준비완료

- 마스터 컨테이너를 먼저 생성한 다음, 마스터의 SSH 공개키를 생성  
- docker-compose.yml 파일에 슬레이브 컨테이너를 추가하고, 앞에서 만든 마스터의 SSH 공개키를 환경 변수 JENKINS_SLAVE_SSH_PUBKEY에 설정  
- links 요소를 사용해 마스터 컨테이너가 슬레이브 컨테이너로 통신할 수 있게 설정  

```bash
$ docker-compose up -d
$ docker-compose ps
```  

#### 마지막 설정  

두 컨테이너를 실행했다고 해서 마스터 젠킨스가 슬레이브 젠킨스를 인식하지는 못한다. 이제 `Jenkins 관리` 페이지에서 `노드 관리`를 선택한 다음, 왼쪽 사이드 메뉴의 `신규 노드 생성` 항목에서 slave01를 추가한다. 노드명은 slave01이라고 입력한다.  

#### 더 나은 컨테이너 개발

컴포즈를 이용해 마스터/슬레이브로 구성된 젠킨스를 구축했다. 이 예제에서는 SSH 접속 설정이나 젠킨 설정 화면에서 슬레이브를 추가하는 등의 작업에서 어느 정도 수작업이 필요했다.  

그러나 이상적인 도커 구성 관리는 애플리케이션을 바로 이용할 수 있는 수준까지 수작업 없이 애플리케이션을 배퐇는 것이 목표이다. 이번에 살펴본 젠킨스 예제는 컨테이너나 컴포즈로 가능한 설정만으로는 모든 구성을  
갖출 수 없었으나, 직접 개발한 애플리케이션에 대한 구성관리를 할 때는 애플리케이션 제어 및 컨테이너 간의 연동을 설정하는 것만으로 충분하도록 애플리케이션 및 도커 이미지, 컨테이너를 구성해야 한다.  

그럼 다음 장에는 설정만으로 도커 구성 관리를 완성할 수 있도록 애플리케이션과 컨테이너를 만들려면 어떻게 해야 하는지 그 기본적인 내용을 알아보겠다.  

# 컨테이너 실전 구축 및 배포

실용적인 컨테이너 구축과 배포에 대해 설명하겠다.  

시스템에서 단일 컨테이너의 비중, 이식성을 고려해 도커 친화적인 애플리케이션을 개발하는 방법, 퍼시스턴스(persistence) 데이터를 다루는 방법, 도커 스윔이나 스택(stack)을 이용한  
컨테이너 배포전략에 대해 알아보자.  

## 애플리케이션과 시스템 내 단일 컨테이너의 적정 비중

단일 컨테이너의 시스템 내 비중은 어떻게 결정해야 하는지 알아보겠다.  

### 컨테이너 1개 = 프로세스 1개?

도커는 애플리케이션 배포에 특화된 가상화 기술이다. 애플리케이션과 인프라를 도커 컨테이너라는 단위로 분리한 것이라 볼 수 있다.  

이런 관점에서 웹 애플리케이션과 워커(worker)형 상주 애플리케이션 프로세스 하나를 하나의 컨테이너로 만드는 방식(컨테이너1개=프로세스1개)이 괜찮게 생각될 수 있다.  
실제로 도커 초기에는 컨테이너 1개 = 프로세스 1개를 반드시 지켜야 한다고 생각하는 사용자가 있어 자주 토론 거리가 됐다.  

과연 이런 생각이 타당할까? 다음 유스 케이스를 통해 이를 고찰해 보겠다.

#### 정기적으로 작업을 실행하는 애플리케이션

정기적으로 어떤 작업을 실행하는 컨테이너가 있다고 가정해 보자.  

스케줄러와 작업이 합쳐진 애플리케이션을 만든다면 컨테이너 1개 = 프로세스 1개 원칙을 지킬 수 있을듯 하다.  
그러나 스케줄러를 직접 갖춘 애플리케이션만 있는 것은 아니다. 대부분은 스케줄러를 외부 기능에 의존한다.  
이 예제의 애플리케이션도 스케줄러 기능을 갖고 있지 않다고 가정하겠다.  

스케줄러 기능이 없는 애플리케이션을 사용해 정기 작업을 실행하려면 cron 을 사용하는 것이 자연스럽다.  

cron은 1개의 상주 프로세스 형태로 동작하는데, 이 스케줄러가 실행하는 작업 역시 하나의 프로세스로 동작한다.  
컨테이너 1개 = 프로세스 1개 방식을 택한다면 cron이 1개 컨테이너고 실행되는 작업이 또 1개의 컨테이너를 차지하는 형태로 구성해야 한다. 이를 실제로 구성하려면 다음과 같은 방법을 생각할 수 있다.  

- 작업 컨테이너 쪽에 작업을 실행하는 트리거 역할을 할 API를 갖추고, cron 컨테이너가 컨테이너 간 통신을 통해 이 API를 호출하는 구조  
- cron 컨테이너에 도커를 구축하고 다시 그 위에서 작업 컨테이너를 실행하는 구조  

cron과 작업 프로세스를 모두 실행하는 방법을 시도해 보자.  

```
cronjob --- task.sh
    |- cron-example
    |- Dockerfile
```  

```sh
#!/bin/sh
echo "[`date`] Hello!" >> /var/log/cron.log
```  

cron-example  

```cron
* * * * * root sh /usr/local/bin/task.sh
```  

> 644  
task.sh, cron-example  

```yaml
FROM ubuntu:16.04

RUN apt update
RUN apt install -y cron

COPY task.sh /usr/local/bin
COPY cron-example /etc/cron.d/
RUN chmod 644 /etc/cron.d/cron-example

CMD ["cron", "-f"]
```  

도커 이미지를 빌드한다.  

```sh
$ docker image build -t example/cronjob:latest .
```  

빌드 이미지를 실행한다.  

```sh
$ docker container run -d --rm --name cronjob example/cronjob:latest
```  

로그 확인  

```sh
$ docker container exec -it cronjob tail -f /var/log/cron.log
```  

#### 자식 프로세스를 너무 의식하지 말것

프로세스를 지나치게 의식하면 컨테이너를 제대로 사용할 수 없다.  

좀더 실용적인 예제를 보자.  
아파치 웹서버는 클라이언트 요청을 받을 때마다 자식 프로세스를 포크하여, 엔진엑스는 마스터 프로세스와 워커프로세스, 캐시관리프로세스가 함께 동작하는 형태이다.  

이런경우까지 컨테이너1개 = 프로세스 1개 원칙을 고수하는 것은 비현실적이다. 도커를 사용하는 이유가 배포 편의성을 위한 것인데, 이쯤 되면 앞뒤가 바뀐 것이라 할 수 있다. 용도에 따라 자연스럽게 프로세스 1개 = 컨테이너 1개가 되는 경우도 있지만, 이를 꼭 지켜야 할 사항으로 생각할 필요는 없다.  

### 컨테이너 1개의 하나의 관심사

애플리케이션을 구축하며 컨테이너 1개 = 프로세스 1개 원칙을 고수하는 것은 무리임을 알았다. 도커는 이 문제를 어떤 관점으로 보고 있을까? 사실 도커의 공식 문서 `Best Pratices for writing Dockerfile`에 이에 대한 공식적인 입장이 담겨 있다.  

Each container should have only one concern  
컨테이너는 하나의 관심사에만 집중해야 한다.  

하나의 관심사란 무엇일까? 이는 다시 말하면 컨테이너 하나가 한 가지 역할이나 문제 영역(도메인)에만 집중해야 한다는 의미다.  

애플리케이션과 컨테이너가 전체 시스템에서 차지해야 하는 적정 비중을 고려하면 `각 컨테이너가 맡을 역할을 적절히 나누고, 그 역할에 따라 배치한 컨테이너를 복제해도 전체구조에서 부작용이 일어나지 않는가?` 를 따져가며 시스템을 설계해야 한다.  

## 컨테이너의 이식성 

도커의 가장 큰 장점은 그 이식성에 있다. 도커를 사용하면 애플리케이션과 인프라를 컨테이너라는 단위로 분리할 수 있으며 도커가 설치된 환경이라면 어떤 호스트 운영 체제와 플랫폼, 온프레미스 및 클라우드 환경에서도 그대로 동작한다.  

이렇게만 애기하면 도커가 완전히 이상적인 환경이 아닌가 생각될 것이다. 방금까지의 설명에서 이상한 부분을 느꼈다면 매우 감이 좋은 사람이다. 아쉽게도 도커의 이식성은 완벽하지 않아서 몇 가지 예외가 존재한다.  

### 커널 및 아키텍처의 차이

도커에서 사용되는 컨테이너형 가상화 기술은 호스트 운영 체제와 커널 리소스를 공유한다. 이는 사실상 도커 컨테이너를 실행하려면 호스트가 특정 CPU 아키텍처 혹은 운영 체제를 사용해야 한다는 의미다.  

예를 들어, 라즈베리 파이 같은 ARM 계열의 armv7I 아키텍처를 채용한 플랫폼에서 인텔의 x86_64 아키텍체에서 빌드한 도커 컨테이너를 실행할 수는 없다.  

`X86_64` 아키텍처에서 실행하는 것을 전체로 만들어진 것이며 다른 아키텍처에서 동작하는 도커에서는 실행이 보장되지 않는다. 도커의 이식성에 대한 가장 큰 오해 중 하나가 바로 이것이다.  

도커는 지금도 지원 플랫폼의 범위를 넓혀가고 있다. 윈도우 지원도 차츰 더 충실해 질 것이다. 최근의 IoT 추세에 따라 ARM 아키텍처 지원도 강화해 나갈 계획이다.  

### 라이브러리와 동적 링크 문제 

애플리케이션이 어떤 라이브러리를 사용하느냐에 따라 이식성을 해치는 경우가 있다. 네이티브 라이브러리를 동적 링크해 사용하는 경우가 특히 그렇다.  

정적링크는 애플리케이션에 사용된 라이브러리를 내부에 포함하는 형태이므로 애플리케이션의 크기가 비대해지는 경향이 있지만 이식성은 뛰어나다 이에 비해 동적 링크는 애플리케이션을 실행할 때 라이브러리가 링크되므로 애플리케이션 크기는 작어지지만 애플리케이션을 실행할 호스트에서 라이브러리를 갖춰야 한다는 문제가 생긴다.  

이 문제는 도커를 사용할 때도 골치를 썩이는데, Dockerfile에 ADD나 COPY 인스트럭션처럼 호스트에서 파일을 복사해올 수 있는 기능이 있으므로 애플리케이션을 컨테이너 외부에서 주입하는 경우도 적지 않다.  
CI를 사용해 애플리케이션 테스트 등을 거쳐 최종적으로 도커 이미지로 패키징하는 형태로 고려해 볼만하다. 되도록 CI에 들이는 시간을 줄이고 싶을 테니까 말이다. CI 처리 중에 생성된 애플리케이션을 그대로 컨테이너에 복사하기만 하면 각 컨테이너에서 이를 다시 컴파일하는 시간을 아낄 수 있다. 이런 방법은 속도도 빠르고 컨테이너 안에서 애플리케이션을 빌드하는 것보다 부하가 가볍기 때문에 괜찮은 방법으로 인식되고 있다.  

다만 이 방법에는 함정이 하나 있다. 동적 링크를 사용한 애플리케이션을 도커에서 사용하는 경우가 여기에 해당한다.  

예를 들어, CI와 컨테이너에서 사용하는 표준 C 라이브러리가 서로 다르다면 CI에서 빌드해 복사해 온 애플리케이션은 컨테이너에서 동작하지 않을 것이다.  

의존성을 유지하기 위해서는 정적링크를 사용하면 되긴 하나 용량이 커진다는 단점이 존재한다.  

이 역시 방지하고 싶다면 모든 빌드 프로세스를 실행하는 도커 컨테이너를 만들고, 그 안에서 애플리케이션을 빌드하면 동일 라이브러리를 사용하는 것이 보장되므로 이를 다른 컨테이너에서 사용해도 문제가 없을 것이다.  

## 도커 친화적인 애플리케이션

컨테이너의 제어와 설정의 관점에서 이를 생각해 보자.  


### 환경 변수 활용

이식성을 중시하는 도커 환경에서는 더욱이 외부에서 동작을 제어할 수 있게 해야 한다.  
도커 컨테이너 형태로 실행되는 애플리케이션의 동작을 제어하는 방법  

- 실행시 인자  
- 설정파일  
- `애플리케이션 동작을 환경 변수로 제어` => 추천  
- 설정 파일에 환경 변수를 포함  

#### 실행 시 인자를 사용

외부에서 값을 주입받을 수 있다는 장점이 있지만, 실행 시 인자가 너무 많아지면 애플리케이션에서 인자를 내부 변수로 매핑해주는 처리가 복잡해지거나 CMD 및 ENTRYPOINT 인스트럭션 내용을 관리하기가 어려워질 수 있다는 단점이 있다. 실행할 때 필요한 인자를 잘 선택하는 안목이 필요하다.  

#### 설정 파일 사용


















## 2. 쿠버네티스

## 3. 호스트

- AWS
  - 가입하기
  - EKS 설정하기
  - 컨테이너 올리기  

- 디지털오션

- GCP

- 알리클라우드

